<!DOCTYPE html>
<html lang="zh-Hant">
<head>
	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<title>AIé«”æ„Ÿç©¿æ­èˆ‡å¦å®¹æ¨è–¦å¹³å°</title>
	<style>
		body {
			font-family: "Microsoft JhengHei", sans-serif;
			background-color: #f7fafd;
			margin: 0;
			padding: 0;
			color: #333;
		}
		header {
			text-align: center;
			padding: 2rem 1rem;
			font-size: 1.8rem;
			font-weight: bold;
			color: #1c1c1c;
		}
		.section {
			max-width: 1000px;
			margin: auto;
			background: #ffffff;
			border-radius: 1rem;
			padding: 2rem;
			box-shadow: 0 4px 12px rgba(0,0,0,0.1);
		}
		.tool-section {
			display: flex;
			flex-wrap: wrap;
			gap: 2rem;
			margin-bottom: 3rem;
		}
		.tool {
			flex: 1 1 45%;
		}
		.tool canvas, .tool video {
			width: 100%;
			border-radius: 0.5rem;
			box-shadow: 0 2px 6px rgba(0,0,0,0.05);
		}
		.tool h2 {
			font-size: 1.4rem;
			margin-bottom: 0.5rem;
			color: #1a1a1a;
		}
		.description {
			margin-top: 0.5rem;
			font-size: 1rem;
			color: #555;
		}
		.suggestion {
			margin-top: 1rem;
		}
		.emoji-box {
			background: #fffbea;
			border-left: 4px solid #ffcc00;
			padding: 1rem;
			border-radius: 0.5rem;
			font-size: 1.1rem;
		}
		#error-msg {
			color: red;
			margin-top: 1rem;
			font-weight: bold;
		}
		header .container {
			display: flex;
			flex-direction: column;
			align-items: center;
			justify-content: center;
		}

		.main-card-img {
			width: 120px; /* å¯ä»¥ä¾éœ€è¦èª¿æ•´å¤§å° */
			margin-bottom: 1rem;
		}
	</style>
</head>
<body>
	<header>
		<div class="container">
			<img src="..\attached_assets\body-scan.png" alt="logo" class="main-card-img">
			<h1>AIé«”æ„Ÿç©¿æ­èˆ‡å¦å®¹æ¨è–¦å¹³å°</h1>
		</div>
	</header>

	<section class="section">
		<div class="tool-section">
			<div class="tool">
				<h2>å¦å®¹å»ºè­°å·¥å…·</h2>
				<video id="video1" autoplay muted playsinline></video>
				<div class="description">ä½¿ç”¨è‡‰éƒ¨ç‰¹å¾µï¼ˆè‡‰å‹ã€çœ‰å½¢ã€è†šè‰²ç­‰ï¼‰æ¨è–¦å¦å®¹èˆ‡ç¾å¦ç”¢å“ã€‚</div>
				<div class="suggestion">
					ğŸ’„ å”‡å½©ã€ç²‰åº•ã€ä¿®å®¹ã€çœ¼å½±ã€è…®ç´…å»ºè­°
				</div>
				<div id="error1" class="error-msg"></div>
			</div>
			<div class="tool">
				<h2>å¦å®¹æƒæçµæœ</h2>
				<canvas id="canvas1"></canvas>
			</div>
			<div class="emoji-box">
			ğŸ˜Š çœ‹èµ·ä¾†æ‚¨å–œæ­¡é€™å€‹ç©¿æ­ï¼å¦å®¹å»ºè­°çš„ï¼Œé‚„æœ‰ä»€éº¼éœ€è¦æˆ‘å¹«å¿™çš„å—ï¼Ÿ
			</div>
		</div>

		<div class="tool-section">
			<div class="tool">
				<h2>ç©¿æ­å»ºè­°ç¥å™¨</h2>
				<video id="video2" autoplay muted playsinline></video>
				<div class="description">ç©¿æ­æ¯”ä¾‹åµæ¸¬èˆ‡é¢¨æ ¼å»ºè­°ï¼Œæå‡æ•´é«”é€ å‹ç¾æ„Ÿã€‚</div>
				<div id="error2" class="error-msg"></div>
			</div>
			<div class="tool">
				<h2>ç©¿æ­æƒæçµæœ</h2>
				<canvas id="canvas2"></canvas>
			</div>
			<div class="emoji-box">
			ğŸ˜Š çœ‹èµ·ä¾†æ‚¨ä¸å¤ªå–œæ­¡é€™ç¨®é¢¨æ ¼ï¼Œè®“æˆ‘æä¾›å…¶ä»–å»ºè­°ï¼
			</div>
		</div>

	</section>

	<script type="module">
		import * as faceMesh from "https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559617/face_mesh.js";
		import * as pose from "https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.js";
		import { Camera } from "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js";

		const video1 = document.getElementById("video1");
		const canvas1 = document.getElementById("canvas1");
		const ctx1 = canvas1.getContext("2d");
		const error1 = document.getElementById("error1");

		const video2 = document.getElementById("video2");
		const canvas2 = document.getElementById("canvas2");
		const ctx2 = canvas2.getContext("2d");
		const error2 = document.getElementById("error2");

		function showCameraError(msg, el) {
			el.textContent = `âš ï¸ ${msg} è«‹ç¢ºèªå·²å…è¨±æ”å½±æ©Ÿæ¬Šé™ï¼Œæˆ–ä½¿ç”¨ http(s) ç¶²å€é–‹å•Ÿæœ¬é é¢ã€‚`;
		}

		try {
			const fm = new faceMesh.FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
			fm.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
			fm.onResults((results) => {
				canvas1.width = video1.videoWidth;
				canvas1.height = video1.videoHeight;
				ctx1.drawImage(results.image, 0, 0, canvas1.width, canvas1.height);
				if (results.multiFaceLandmarks) {
					for (const landmarks of results.multiFaceLandmarks) {
						ctx1.fillStyle = "#00FF00";
						landmarks.forEach(p => ctx1.fillRect(p.x * canvas1.width, p.y * canvas1.height, 2, 2));
					}
				}
			});
			const cam1 = new Camera(video1, {
				onFrame: async () => await fm.send({ image: video1 }),
				width: 400,
				height: 500
			});
			cam1.start();
		} catch (err) {
			showCameraError("å¦å®¹å»ºè­°å·¥å…·ç„¡æ³•å•Ÿå‹•æ”å½±æ©Ÿã€‚", error1);
		}

		try {
			const ps = new pose.Pose({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}` });
			ps.setOptions({ modelComplexity: 1, smoothLandmarks: true, enableSegmentation: false, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
			ps.onResults((results) => {
				canvas2.width = video2.videoWidth;
				canvas2.height = video2.videoHeight;
				ctx2.drawImage(results.image, 0, 0, canvas2.width, canvas2.height);
				if (results.poseLandmarks) {
					ctx2.fillStyle = "#FF0000";
					results.poseLandmarks.forEach(p => ctx2.fillRect(p.x * canvas2.width, p.y * canvas2.height, 3, 3));
				}
			});
			const cam2 = new Camera(video2, {
				onFrame: async () => await ps.send({ image: video2 }),
				width: 400,
				height: 500
			});
			cam2.start();
		} catch (err) {
			showCameraError("ç©¿æ­å»ºè­°å·¥å…·ç„¡æ³•å•Ÿå‹•æ”å½±æ©Ÿã€‚", error2);
		}
	</script>
</body>
</html>

